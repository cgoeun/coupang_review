{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "\n",
    "data = pd.read_csv('./reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star</th>\n",
       "      <th>date</th>\n",
       "      <th>vendor</th>\n",
       "      <th>review</th>\n",
       "      <th>help</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2022.03.12</td>\n",
       "      <td>쿠팡(주)</td>\n",
       "      <td>굿굿 ♡ ♥  내돈내산 솔직담백 리뷰 입니다 !  ♥ 항상 제품을 구매하기전 후기를...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star        date vendor                                             review  \\\n",
       "0     5  2022.03.12  쿠팡(주)  굿굿 ♡ ♥  내돈내산 솔직담백 리뷰 입니다 !  ♥ 항상 제품을 구매하기전 후기를...   \n",
       "\n",
       "   help  \n",
       "0    12  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192977"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) # 총 192977개의 리뷰를 수집했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text(text):\n",
    "    pattern = '[^\\w\\s]'         # 특수기호제거'[^\\w\\sㄱ-ㅎㅏ-ㅣ]' \n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    text = re.sub(pattern='[\\s]+', repl=' ', string=text)\n",
    "\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanspell import spell_checker\n",
    "def data_preprocessing(review):\n",
    "    return spell_checker.check(review).checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(find_text)\n",
    "data['review_r'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(105867, 110001): \n",
    "    # 이런 식으로 10만 단위씩 끊어서 실행 및 저장. \n",
    "    # 에러 시 해당 번호(idx)부터 재실행\n",
    "    # 하다가 빈번한 에러로 인해 try-except 적용\n",
    "    # 미리 공백('')을 기본값으로 생성했기 때문에 큰 문제 없음\n",
    "    try :\n",
    "        data['review_r'][idx] = spell_checker.check(data.loc[idx,'review']).checked\n",
    "    except : pass\n",
    "    print(idx)\n",
    "data.to_csv('./reviews_r.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for idx, d in enumerate(data['review_r']):\n",
    "    if len(d) <1 : \n",
    "        print(d)\n",
    "        data['review_r'][idx] = np.nan\n",
    "# 공백 제거가 안 돼서 다시 Null로 만들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "'''\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 146558 entries, 0 to 146557\n",
    "Data columns (total 6 columns):\n",
    " #   Column    Non-Null Count   Dtype \n",
    "---  ------    --------------   ----- \n",
    " 0   star      146558 non-null  int64 \n",
    " 1   date      146558 non-null  object\n",
    " 2   vendor    146558 non-null  object\n",
    " 3   review    146558 non-null  object\n",
    " 4   help      146558 non-null  int64 \n",
    " 5   review_r  144882 non-null  object\n",
    "dtypes: int64(2), object(4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset='review_r', inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "del data['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리된 컬럼 review_r을 만들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized'] = data['review_r'].apply(lambda x: okt.morphs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized'][0] # 형태소 단위로 잘 끊겨서 리스트로 담겨 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_list = np.hstack(data['tokenized'].values).tolist()\n",
    "result = ' '.join(s for s in noun_list)\n",
    "# 단어 빈도를 확인하기 위해 하나의 문자열로 만들었다.\n",
    "count = Counter(okt.nouns(result))\n",
    "noun_list_1000 = count.most_common(1000)\n",
    "for w in noun_list_1000:\n",
    "    print(w)\n",
    "# 근데 봐도 잘 모르겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./reviews_token.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새 파일로 작업했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./reviews_token.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = pd.read_csv('./word_dict.csv')\n",
    "word_list\n",
    "# 엑셀로 만든 단어 사전 리스트를 읽어 왔다.\n",
    "# [word, pos, neg, rat, sign]\n",
    "# 단어, 긍정가중치합, 부정가중치합, 긍정/부정 또는 부정/긍정 비율, 긍정이 많을 경우 +, 부정이 많을 경우 -의 정보로 구성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "참고로 pos와 neg는 이렇게 구했다.\n",
    "1) 일단 구하기\n",
    "negative_point = 0.0\n",
    "positive_point = 0.0\n",
    "\n",
    "for idx, word in enumerate(word_list) :\n",
    "    try:\n",
    "        for i in range(len(data)): \n",
    "            if re.search(word, data['review_r'].iloc[i]) or re.search(word, data['review'].iloc[i]):\n",
    "                if data.iloc[i]['star'] == 5 : \n",
    "                    positive_point += 4/101203*144882\n",
    "                elif data.iloc[i]['star'] == 4 :\n",
    "                    positive_point += 3/21465*144882\n",
    "                    negative_point += 1/21465*144882 \n",
    "                elif data.iloc[i]['star'] == 3 :\n",
    "                    positive_point += 2/8661*144882 \n",
    "                    negative_point += 2/8661*144882 \n",
    "                elif data.iloc[i]['star'] == 2 :\n",
    "                    positive_point += 1/3809*144882 \n",
    "                    negative_point += 3/3809*144882 \n",
    "                elif data.iloc[i]['star'] == 1 :\n",
    "                    negative_point += 4/9744*144882   \n",
    "                    \n",
    "        dictionary_df.iloc[idx,1] = positive_point\n",
    "        dictionary_df.iloc[idx,2] = negative_point\n",
    "        negative_point = 0.0\n",
    "        positive_point = 0.0\n",
    "    except Exception as e : print(idx, e)\n",
    "    \n",
    "2) 조건 미달 제거하기\n",
    "dictionary_df['rat'] = 0.0\n",
    "idx_list = []\n",
    "for idx in range(len(dictionary_df)):\n",
    "    if dictionary_df.iloc[idx,2]>dictionary_df.iloc[idx,1]:\n",
    "        dictionary_df.iloc[idx,3] = dictionary_df.iloc[idx,2]/dictionary_df.iloc[idx,1]\n",
    "    else :\n",
    "        dictionary_df.iloc[idx,3] = dictionary_df.iloc[idx,1]/dictionary_df.iloc[idx,2]\n",
    "    if dictionary_df.iloc[idx,3] < 2 or dictionary_df.iloc[idx,3] == float('inf') or (dictionary_df.iloc[idx,2]<1000 and dictionary_df.iloc[idx,1]):\n",
    "        idx_list.append(idx)\n",
    "\n",
    "save = dictionary_df.drop(idx_list)\n",
    "\n",
    "3) 부호 구하기\n",
    "save['sign'] = 1\n",
    "for idx in range(len(save)):\n",
    "    save['sign'].iloc[idx] = 1 if save['pos'].iloc[idx] >= save['neg'].iloc[idx] else -1\n",
    "\n",
    "save['sign'].value_counts()\n",
    "save.to_csv('./point_dict_2.0.csv', index=False)\n",
    "\n",
    "4) 유효성 확인하기\n",
    "data['valid'] = 0\n",
    "data['star'].value_counts()\n",
    "\n",
    "for i in range(len(data)): # 4나 5는 긍정, 1, 2, 3은 부정으로 임의 처리\n",
    "    if data['label'].iloc[i] == 1 and (data['star'].iloc[i] == 4 or data['star'].iloc[i] == 5) :\n",
    "        data['valid'].iloc[i] = 1\n",
    "    elif data['label'].iloc[i] == 0 and (data['star'].iloc[i] == 1 or data['star'].iloc[i] == 2 or data['star'].iloc[i] == 3):\n",
    "        data['valid'].iloc[i] = 1\n",
    "        \n",
    "data['valid'].value_counts()\n",
    "valid_data = data[data['valid']==1]\n",
    "valid_data['star'].value_counts() # 일치하는 데이터만 쓸까 생각 중\n",
    "valid_data.to_csv('./valid_data.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_df = pd.DataFrame(word_list['word'].tolist(), columns=['word'])\n",
    "dictionary_df['pos'] = 0.0\n",
    "dictionary_df['neg'] = 0.0\n",
    "dictionary_df\n",
    "# 야매로 만들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['star'].value_counts()\n",
    "# 별점의 비율을 확인해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = 1 # 리뷰에서 긍정적인 리뷰가 더 많은 편이어서 기본값을 1로 주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)): \n",
    "    point = 0\n",
    "    for idx, (word, w) in enumerate(zip(word_list['word'], word_list['sign'])) :\n",
    "        if re.search(word, data['review_r'].iloc[i]) or re.search(word, data['review'].iloc[i]):\n",
    "            point += w #* rat\n",
    "    if point >= 0 :\n",
    "        data['label'].iloc[i] = 1\n",
    "    else : \n",
    "        data['label'].iloc[i] = 0\n",
    "# 전처리된 리뷰 또는 원본 리뷰에서 해당 단어를 확인해서 확인되는 경우 가중치(- 또는 +)를 누적 합산하도록 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하다가 데이터 라벨링에 대한 고민 끝에 갈아 엎고 5를 긍정, 1, 2를 부정으로 하여 재시작해보도록 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./reviews_token.csv')\n",
    "data['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨링\n",
    "for i in range(len(data)):\n",
    "    if data['star'].iloc[i] == 5 :\n",
    "        data['label'].iloc[i] = 1\n",
    "    elif data['star'].iloc[i] == 1 or data['star'].iloc[i] == 2 : #or data['star'].iloc[i] == 3 or data['star'].iloc[i] == 4\n",
    "        data['label'].iloc[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건에 맞는 데이터만 사용하기\n",
    "data2 = data[data['star']==1]\n",
    "data2 = data2.append(data[data['star']==2])\n",
    "data2 = data2.append(data[data['star']==5])\n",
    "data2.reset_index(inplace=True)\n",
    "data2\n",
    "# 14만여 개 중 약 3만 건이 제외된다. (3, 4 별점 데이터)\n",
    "# 총 114756 개 데이터\n",
    "# 1    101203, 0     13553 (긍정댓글 : 부정댓글)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kss import split_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = pd.DataFrame(columns=['sents', 'label'])\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sents, label in zip(data2['review_r'], data2['label']):\n",
    "  for sent in split_sentences(sents):\n",
    "#  tokenized.append(bert_tokenizer(sent))\n",
    "    t = bert_tokenizer.encode_plus(sent,\n",
    "                                  add_special_tokens=True,\n",
    "                                  max_length=30,\n",
    "                                  padding='max_length',\n",
    "                                  return_attention_mask=True)\n",
    "    tokenized = pd.concat([tokenized, pd.Series([t, label])])\n",
    "# split_sentences로 문장 단위로 끊어서 한 문장씩 토크나이즈 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('web')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5e7e8f872320555b50ac54370c74f1f286190517b375e4238474aa45f483ea0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
